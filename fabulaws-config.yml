  # "florida" floridaopendebate
  # "testing": demopenquestions
  # "staging": staging.presidentialopenquestions
  # "presidential": presidentialopenquestions
  # "staging01": staging.opendebatequestions
  # "prod01": opendebatequestions

  instance_settings:
    # http://uec-images.ubuntu.com/releases/trusty/release/
    ami: ami-35d6f95f # us-east-1 14.04.3 LTS 64-bit hvm-ssd
    key_prefix: 'opendebates-'
    admin_groups: [admin, sudo]
    run_upgrade: true
    # Secure directories, volume, and filesystem info
    app_root: /opendebates # no trailing /
    fs_type: ext4
    fs_encrypt: false
    # create swap of swap_multiplier * available RAM
    swap_multiplier: 1

## REMOTE SETTINGS ##
  deploy_user: opendebates
  webserver_user: opendebates-web
  database_host: localhost
  database_user: opendebates
  home: /home/opendebates # no trailing /
  python: /usr/bin/python2.7

## LOCAL / PROJECT SETTINGS ##
  disable_known_hosts: true
  ssh_keys: deployment/users/
  password_names: [database_password, broker_password, smtp_password,
                   newrelic_license_key, newrelic_api_key, s3_secret,
                   secret_key, dbbackup_access_key, dbbackup_access_secret,
                   syslog_server, recaptcha_site_key, recaptcha_secret,
                   use_captcha, mixpanel_key, email_from, optimizely_key,
                   basic_auth_username, basic_auth_password]
  project: opendebates
  wsgi_app: opendebates.wsgi:application
  requirements_file: requirements/base.txt
  requirements_sdists:
  settings_managepy: opendebates.local_settings
  static_html:
    upgrade_message: deployment/templates/html/503.html
    healthcheck_override: deployment/templates/html/healthcheck.html
  localsettings_template: deployment/templates/local_settings.py
  logstash_config: deployment/templates/logstash.conf
  backup_key_fingerprint:
  vcs_cmd: git # or hg
  latest_changeset_cmd: git rev-parse HEAD # hg id -i # or git rev-parse HEAD
  repo: git@github.com:caktus/django-opendebates.git
# Mapping of Fabric deployments and environments to the branch names
# that should be deployed.
  branches:
    opendebates:
      testing: master
      staging: develop
      florida: master
      presidential: develop
      staging01: develop
      prod01: develop

## SERVER SETTINGS ##
  use_basic_auth:
    testing: True
    staging: True
    florida: False
    presidential: False
    staging01: True
    prod01: False

# Local server port for pgbouncer
  pgbouncer_port: 5432

  less_version: 2.7.1

# Local server ports used by Gunicorn (the Django apps server)
  server_ports:
    testing: 8000
    staging: 8001
    florida: 8002
    presidential: 8003
    staging01: 8004
    prod01: 8005


# Whether we're hosting static files on our webservers ('local')
# or somewhere else ('remote')
  static_hosting: local

# Mapping of celery worker names to options
  celery_workers:
    main: -c 10

# Start this many Gunicorn workers for each CPU core
  gunicorn_worker_multiplier: 4

# Mapping of environment names to domain names. Used to update the
# primary site in the database after a refresh and to set ALLOWED_HOSTS
# Note that the first domain in the list must not be a wildcard as it
# is used to update a Site object in the database.
# Wildcard format used per ALLOWED_HOSTS setting
  site_domains_map:
    testing:
    - demopenquestions.com
    - testing.demopenquestions.com
    - opendebates-testing-lb-476601241.us-east-1.elb.amazonaws.com
    - www.demopenquestions.com
    staging:
    - staging.demopenquestions.com
    - staging.presidentialopenquestions.com
    florida:
    - floridaopendebate.com
    - www.floridaopendebate.com
    presidential:
    - presidentialopenquestions.com
    - www.presidentialopenquestions.com
    staging01:
    - staging.opendebatequestions.com
    prod01:
    - opendebatequestions.com
    - www.opendebatequestions.com

## ENVIRONMENT / ROLE SETTINGS ##

  default_deployment: opendebates
  deployments:
  - opendebates
  environments:
  - testing
  - staging
  - florida
  - presidential
  - staging01
  - prod01
  production_environments:
  - florida
  - presidenetial
  - prod01
  valid_roles:
  - cache
  - db-master
  - db-slave
  - web
  - worker

## AWS SETTINGS ##

  region: us-east-1
  avail_zones:
  - b
  - d

# Mapping of role to security group(s):
  security_groups:
    db-master: [opendebates-sg, opendebates-db-sg]
    db-slave: [opendebates-sg, opendebates-db-sg]
    cache: [opendebates-sg, opendebates-session-sg, opendebates-cache-sg, opendebates-queue-sg]
    worker: [opendebates-sg, opendebates-worker-sg]
    web: [opendebates-sg, opendebates-web-sg]

# Mapping of environment and role to EC2 instance types (sizes)
# Except for very small instance types where it doesn't matter as much,
# it's best to use 'c3' or 'm3' generation instances with local SSD storage
# for 'web' instances that will be used to create AMIs (and use a small
# volume_size), as it dramatically speeds up AMI creation (by ~10 min).
# The c4 and m4 suite of instances support EBS optimization by default and
# may be better for database or other high-I/O services:
# http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html#ebs-optimization-support
# Additionally, 2xlarge or higher instance types are needed to get >= 1000 Mbps
# on the network. This is important for the cache server which might not have
# a lot of CPU load but will be transfering lots of data back & forth. See:
# http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-ec2-config.html
  instance_types:
    testing:
      cache: c4.2xlarge # for 1000Mbps network
      db-master: m4.2xlarge
      db-slave: m4.2xlarge
      web: c3.xlarge # for faster AMI creation (no swap file)
      worker: m4.large
    staging:
      cache: t2.micro
      db-master: t2.small
      db-slave: t2.small
      web: t2.micro
      worker: t2.micro
    staging01:
      cache: t2.micro
      db-master: t2.small
      db-slave: t2.small
      web: t2.micro
      worker: t2.micro
    florida:
      cache: c4.large
      db-master: m4.2xlarge
      db-slave: m4.2xlarge
      web: c3.xlarge # for faster AMI creation (no swap file)
      worker: m4.large
    presidential:
      cache: t2.micro
      db-master: t2.small
      db-slave: t2.small
      web: t2.micro
      worker: t2.micro
    prod01:
      cache: t2.micro
      db-master: t2.small
      db-slave: t2.small
      web: t2.micro
      worker: t2.micro

# Mapping of Fabric environment names to AWS load balancer names.  Load
# balancers can be configured in the AWS Management Console.
  load_balancers:
    opendebates:
      testing:
      - opendebates-testing-lb
      staging:
      - opendebates-staging-lb
      florida:
      - opendebates-florida-lb
      presidential:
      - opendebates-presidential-lb
      staging01:
      - opendebates-staging01-lb
      prod01:
      - opendebates-prod01-lb

# Mapping of Fabric environment names to AWS auto scaling group names. Auto
# scaling groups can be configured in the AWS Management Console.
  auto_scaling_groups:
    opendebates:
      testing: opendebates-testing-ag
      staging: opendebates-staging-ag
      florida: opendebates-florida-ag
      presidential: opendebates-presidential-ag
      staging01: opendebates-staging01-ag
      prod01: opendebates-prod01-ag

# Mapping of Fabric environment and role to Elastic Block Device sizes (in GB).
# If you have any 'm4' or 'c4' instances, make sure these are large enough to
# hold your data plus a swap file (these instance types have no local storage).
  volume_sizes:
    testing:
      cache: 25 # 10 GB data + 15 GB swap
      db-master: 132 # 100 GB data + 32 GB swap
      db-slave: 132 # 100 GB data + 32 GB swap
      web: 10 # 10 GB data (no swap)
      worker: 66 # 50 GB data + 16 GB swap
    staging:
      cache: 10
      db-master: 100
      db-slave: 100
      web: 10
      worker: 50
    staging01:
      cache: 10
      db-master: 100
      db-slave: 100
      web: 10
      worker: 50
    florida:
      cache: 25 # 10 GB data + 15 GB swap
      db-master: 282 # 250 GB data + 32 GB swap
      db-slave: 282 # 250 GB data + 32 GB swap
      web: 10 # 10 GB data (no swap)
      worker: 66 # 50 GB data + 16 GB swap
    presidential:
      cache: 25 # 10 GB data + 15 GB swap
      db-master: 282 # 250 GB data + 32 GB swap
      db-slave: 282 # 250 GB data + 32 GB swap
      web: 10 # 10 GB data (no swap)
      worker: 66 # 50 GB data + 16 GB swap
    prod01:
      cache: 25 # 10 GB data + 15 GB swap
      db-master: 282 # 250 GB data + 32 GB swap
      db-slave: 282 # 250 GB data + 32 GB swap
      web: 10 # 10 GB data (no swap)
      worker: 66 # 50 GB data + 16 GB swap

# Mapping of Fabric environment and role to Elastic Block Device volume types
# Use SSD-backed storage (gp2) for all servers. Change to 'standard' for slower
# magnetic storage.
  volume_types:
    cache: gp2
    db-master: gp2
    db-slave: gp2
    web: gp2
    worker: gp2

  app_server_packages:
    - python2.7-dev
    - libpq-dev
    - libmemcached-dev
    - supervisor
    - mercurial
    - git
    - build-essential
    - stunnel4
    - pgbouncer
    - postgresql-client-9.3

  db_settings:
    # for help adjusting these settings, see:
    # http://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server
    # http://wiki.postgresql.org/wiki/Number_Of_Database_Connections
    # http://thebuild.com/presentations/not-my-job-djangocon-us.pdf
    postgresql_settings:
      # Settings to apply to Postgres servers
      # You can put anything here from postgresql.conf

      # connections
      max_connections: '80' # _active_ connections are limited by pgbouncer

      # replication settings
      wal_level: 'hot_standby'
      hot_standby: 'on'
      hot_standby_feedback: 'on'
      max_wal_senders: '3'
      wal_keep_segments: '3000' # during client deletion 50 or more may be generated per minute; this allows an hour

      # resources - let pgtune set these based on actual machine resources
      # shared_buffers: '8GB' # 25% of available RAM, up to 8GB
      # work_mem: '750MB' # (2*RAM)/max_connections
      # maintenance_work_mem': '1GB' # RAM/16 up to 1GB; high values aren't that helpful
      # effective_cache_size': '48GB' # between 50-75%, should equal free + cached values in `top`

      # checkpoint settings
      wal_buffers: '16MB'
      checkpoint_completion_target: '0.9'
      checkpoint_timeout: '10min'
      checkpoint_segments: '256' # if checkpoints are happening more often than the timeout, increase this up to 256

      # logging
      log_min_duration_statement: '500'
      log_checkpoints: 'on'
      log_lock_waits: 'on'
      log_temp_files: '0'
      log_destination: 'syslog'

      # write optimizations
      commit_delay: '4000' # delay each commit this many microseconds in case we can do a group commit
      commit_siblings: '5' # only delay if at least N transactions are in process

      # index usage optimizations
      random_page_cost: '2' # our DB servers have a lot of RAM and may tend to prefer Seq Scans if this is too high

    # More Postgres-related settings.
    # How to install Postgres:
    postgresql_packages:
      - postgresql
      - libpq-dev
      - postgresql-contrib
    # Whether and how to apply pgtune
    postgresql_tune: true
    postgresql_tune_type: Web
    # Kernel sysctl settings to change
    postgresql_shmmax: 107374182400  # 100 GB
    postgresql_shmall: 26214400  # 100 GB / PAGE_SIZE (4096)
    # Networks to allow connections from
    postgresql_networks:
      - '0.0.0.0/0'
      - '10.0.0.0/8'
      - '172.0.0.0/8'
    # Whether to disable the Linux out-of-memory killer
    postgresql_disable_oom: true
